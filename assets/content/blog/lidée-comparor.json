{
  "date": "2020-10-22T10:26:00.158Z",
  "img": "/img/goldimg.png",
  "title": "L'idée Compar'Or",
  "description": "Sortir de sa zone de confort : partir à l'aventure, combattre les bugs et rentrer victorieux ",
  "body": "Pendant la période de confinement, je me suis fixé comme objectif de créer une application web qui permettrait de « level-up » mes compétences en Javascript, et en architecture d'application en général.\n\nJ’ai donc lu plusieurs articles au sujet des bonnes idées de projets perso pour s’entrainer, élargir son portfolio de développeur web, et ainsi se créer des opportunités d’emploi. Sur la plupart des articles que j’ai consulté, les idées étaient les suivantes : créer une todo app, une app météo, un blog…\n\nCes projets, souvent accompagné d’une multitude de tutoriels, sont très utiles pour découvrir les divers facettes du développement web.\\\nCependant, comme l'explique [Rayed Benbrahim](https://practicalprogramming.fr/author/rayed-benbrahim/) dans son article [\"Les tutos ne t’aident pas à progresser !](https://practicalprogramming.fr/pourquoi-les-tutos-ne-taident-pas/)\", il n’y a pas de magie, ni de raccourcis à prendre pour devenir développeur. \n\nLa seule solution est de **sortir de sa zone de confort** en créant son propre projet, et de faire face aux bugs comme Gandalf face au Balrog dans les mines de la Moria.\n\nMon objectif s’est alors précisé : je veux créer une app spécifique, sur mesure, avec mon API rien qu’à moi.  Pourquoi ? \\\nSimplement pour m’éloigner de toute aide trop accessible sur des projets aussi populaires, et ainsi me rapprocher au mieux du développement web en entreprise. Partir à l'aventure avec comme seul support la documentation des technologies que j’utilise, et quelques forums sur les bugs rencontrés. \n\nQuelques jours après cette première réflexion, je suis tombé sur un article au sujet du webscraping que j’ai trouvé fort intéressant. \\\nLe **webscraping** est une technique qui permet d’extraire les données d’un site en utilisant un script.  J’ai vite compris que cette méthode allait élargir grandement mes possibilités. En effet, au lieu d’utiliser une API public avec des données qui n’inspire pas ma créativité, j’avais maintenant le choix de créer la mienne avec des données ‘webscrapées’ !\n\nQuelques jours plus tard, mon oncle me contacte pour parler d’investissement sur le marché des métaux précieux et plus particulièrement sur le marché de l’or. Il termine en me demandant de lui trouver le meilleur site de vente de pièces d'or en ligne. Après recherche, je me rend compte que les prix varient d’un site à l’autre :  d’une vingtaine d'euros pour les 20 Francs Napoléon, et jusqu’à 200 euros de différence pour les pièces avec plus de valeur.\n\nFaire son choix est compliqué, on passe d'un onglet à l’autre, on compare les prix… De plus, certains sites ne sont pas transparent : il faut demander un devis, chercher le prix de livraison, la prime, et calculer soi-même.  Je commence par perdre patience, je me rend donc sur Google pour trouver un bon comparateur... Et là, rien ou presque : un site avec des prix non à jour et des liens inactifs. \\\nBingoo !  Je venais tout juste de trouver l’idée de mon projet : **un comparateur de prix de pièces d’or** ! *et merci tonton hehe*\n\nLe cours de l’or est en constante évolution, ce qui engendre une modification des prix en temps réel. Ainsi, pour gagner la confiance de l'utilisateur de mon app, je dois tenir à jour les prix affichés en fonction des sites que je compare : à la minute près, le prix affiché sur mon site devra être le même que le prix affiché sur le site de vente de pièces d’or. C’était pour moi la fonctionnalité principale de mon projet : celle qui allait faire que mon app soit pertinente ou non. Je me suis donc empressé de tester si mon idée était réalisable dans un simple fichier Javascript, en utilisant la librairie **Puppeteer** de Google couplée au module **Cron**. \n\n**Puppeteer** permet de contrôler un navigateur Chromium coté back-end. L'idée est d'écrire un script avec toutes les tâches que le navigateur devra réaliser : ouvrir une nouvelle page, aller à l'URL donné, récupérer du contenu du site visité, fermer la page, et une multitude d'autres actions. \n\n**Cron** me permettra de planifier le lancement de mon script Puppeteer : tous les jours, toutes les heures, toutes les 2 minutes… Ce module me permettra de mettre à jour les prix en relançant le script !\n\n## Création du script \"scraper.js\"\n\n### **1.** Importation des modules\n\n![import-module scraping.js](/img/import-modules.png \"test scraping prix pièce d'or\")\n\nJ'importe les modules nécessaires et je déclare la constante qui contiendra l'adresse URL où se trouve les données que je veux récuperer.\n\n### **2.** Je déclare la fonction configureBrowser()\n\n![configureBrowser scraping.js](/img/configurebrowser-.png \"configureBrowser scraping.js\")\n\n L'exécution du code à l'intérieur de cette fonction se fera donc de manière asynchrone, étape par étape avec un système de file d'attente (event loop) : Fais ceci, et \"attends\" que ceci soit terminé avant de passer à la ligne suivante. Cela permet de bloquer l'exécution du code jusqu'à la fin de l'opération grâce au mot-clef \"await\". Dans mon cas, utiliser une fonction asynchrone est indispensable sinon mon script échouerai à l’exécution. En effet, je suis obligé d'attendre que le navigateur soit lancer avant d'ouvrir un nouvel onglet, et ensuite d'attendre que le nouvel onglet soit ouvert pour visiter une URL.\n\nCette fonction va donc :\n\n* Créer une instance de Chrome en utilisant la méthode puppeteer.launch()\n* Créer un nouvel onglet dans ce même navigateur en utilisant la méthode browser.newPage() \n* Se rendre à l’URL que j’ai déclaré à l’étape 1 en passant ma constante en paramètre de la méthode goto()\n\n**3.** Je déclare la fonction scrapePrice()\n\n![scrapePrice scraping.js](/img/scrapeprice-.png \"scrapePrice scraping.js\")\n\n![main scraping.js](/img/main-.png \"main scraping.js\")\n\n![cronJob scraping.js](/img/job-.png \"cronJob scraping.js\")\n\n![resultat scraping](/img/resultat-scaping.png \"resultat scraping\")"
}